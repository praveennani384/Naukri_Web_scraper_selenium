{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cb0dcdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1\n",
      "Scraping page 2\n",
      "Scraping page 3\n",
      "Scraping page 4\n",
      "Scraping page 5\n",
      "Scraping page 6\n",
      "Scraping page 7\n",
      "Scraping page 8\n",
      "Scraping page 9\n",
      "Scraping page 10\n",
      "Job details exported to job_details.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import time\n",
    "import csv\n",
    "\n",
    "def scrape_job_details(url):\n",
    "    try:\n",
    "        # Instantiate a WebDriver (assuming ChromeDriver is installed)\n",
    "        options = webdriver.ChromeOptions()\n",
    "        options.add_argument('--ignore-certificate-errors')\n",
    "        options.add_argument('--ignore-ssl-errors')\n",
    "        driver = webdriver.Chrome(options=options)\n",
    "        \n",
    "        # Open the URL in the WebDriver\n",
    "        driver.get(url)\n",
    "        \n",
    "        # Wait for the page to load\n",
    "        time.sleep(5)\n",
    "        \n",
    "        # Scraping job details from multiple pages\n",
    "        job_details = []\n",
    "        for page in range(1, 11):  # Scrape up to 10 pages\n",
    "            print(\"Scraping page\", page)\n",
    "            \n",
    "            # Extract job details using XPath expressions\n",
    "            job_titles = driver.find_elements(By.XPATH, '//div[@class=\"cust-job-tuple layout-wrapper lay-2 sjw__tuple \"]/div[@class=\" row1\"]/a')\n",
    "            company_names = driver.find_elements(By.XPATH, '//div[@class=\"cust-job-tuple layout-wrapper lay-2 sjw__tuple \"]/div[@class=\" row2\"]/span/a[@class=\" comp-name mw-25\"]')\n",
    "            locations = driver.find_elements(By.XPATH, '//span[@class=\"locWdth\"]')\n",
    "            \n",
    "            # Append job details to the list\n",
    "            for job_title, company_name, location in zip(job_titles, company_names, locations):\n",
    "                job_details.append({\n",
    "                    \"Job Title\": job_title.text.strip(),\n",
    "                    \"Company Name\": company_name.text.strip() if company_name.text else \"N/A\",\n",
    "                    \"Location\": location.text.strip()\n",
    "                })\n",
    "            \n",
    "            # Click on the next page button\n",
    "            next_page_button = driver.find_element(By.XPATH, '(//a[@class=\"styles_btn-secondary__2AsIP\"])[1]')\n",
    "            actions = ActionChains(driver)\n",
    "            actions.move_to_element(next_page_button).perform()\n",
    "            next_page_button.send_keys(Keys.ENTER)\n",
    "            \n",
    "            # Wait for the page to load\n",
    "            time.sleep(5)\n",
    "        \n",
    "        # Export job details to CSV\n",
    "        with open('job_details.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "            fieldnames = ['Job Title', 'Company Name', 'Location']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            \n",
    "            writer.writeheader()\n",
    "            for job_detail in job_details:\n",
    "                writer.writerow(job_detail)\n",
    "                \n",
    "        print(\"Job details exported to job_details.csv\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", str(e))\n",
    "        \n",
    "    finally:\n",
    "        # Close the WebDriver\n",
    "        driver.quit()\n",
    "\n",
    "# URL to scrape\n",
    "url = 'https://www.naukri.com/jobs-in-india?roleTypeFilterGid=169&wfhType=0&clusters=roleGid,wfhType'\n",
    "\n",
    "# Call the function to scrape job details\n",
    "scrape_job_details(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3ca20f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
